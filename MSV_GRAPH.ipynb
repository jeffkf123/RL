{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SERVER\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, server_id, ip_address, total_cpu, total_memory, total_bandwidth, network_distance, hosted_services=None):\n",
    "        self.server_id = server_id\n",
    "        self.network_distance = network_distance\n",
    "        self.ip_address = ip_address\n",
    "        self.total_cpu = total_cpu\n",
    "        self.total_memory = total_memory\n",
    "        self.total_bandwidth = total_bandwidth\n",
    "        self.available_cpu = total_cpu  # Initially, all resources are available\n",
    "        self.available_memory = total_memory\n",
    "        self.available_bandwidth = total_bandwidth\n",
    "        self.hosted_services = hosted_services if hosted_services is not None else []\n",
    "\n",
    "    def calculate_agg_resources(self):\n",
    "        \"\"\"Calculate the average resource utilization as an aggregate metric.\"\"\"\n",
    "        return (self.available_cpu + self.available_memory + self.available_bandwidth) / 3\n",
    "\n",
    "    \n",
    "    def add_service_function(self, service_function):\n",
    "        self.hosted_services.append(service_function)\n",
    "\n",
    "    def remove_service_function(self, service_function):\n",
    "        self.hosted_services.remove(service_function)\n",
    "\n",
    "    def list_service_functions(self):\n",
    "        return self.hosted_services\n",
    "    \n",
    "    def calculate_latency_priority(self, microservice):\n",
    "        \"\"\"Simulate latency based on network distance and server load, in real life we would have the microservice ping the server.\"\"\"\n",
    "        base_latency = self.network_distance * 0.5  # Simplified calculation\n",
    "        return base_latency\n",
    "    \n",
    "    def meets_requirements(self, cpu_requirement, memory_requirement, bandwidth_requirement):\n",
    "        \"\"\"Check if the server has enough resources to host the microservice.\"\"\"\n",
    "        return (self.available_cpu >= cpu_requirement and\n",
    "                self.available_memory >= memory_requirement and\n",
    "                self.available_bandwidth >= bandwidth_requirement)\n",
    "    def deploy_microservice(self, microservice):\n",
    "        #Deploy service and subtract required resources\n",
    "        if not self.meets_requirements(microservice.cpu_requirement, microservice.memory_requirement, microservice.bandwidth_requirement):\n",
    "            return False  # Deployment fails due to insufficient resources\n",
    "        \n",
    "        self.available_cpu -= microservice.cpu_requirement\n",
    "        self.available_memory -= microservice.memory_requirement\n",
    "        self.available_bandwidth -= microservice.bandwidth_requirement\n",
    "        self.hosted_services.append(microservice.service_id)\n",
    "        microservice.server=self\n",
    "        return True\n",
    "\n",
    "    def remove_microservice(self, microservice):\n",
    "        #remove a service and re-add used resources to server\n",
    "        if microservice.service_id in self.hosted_services:\n",
    "            self.available_cpu += microservice.cpu_requirement\n",
    "            self.available_memory += microservice.memory_requirement\n",
    "            self.available_bandwidth += microservice.bandwidth_requirement\n",
    "            self.hosted_services.remove(microservice.service_id)\n",
    "            microservice.server= None\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"Server(ID={self.server_id}, IP={self.ip_address}, \"\n",
    "                f\"CPU={self.available_cpu}, Memory={self.available_memory}, \"\n",
    "                f\"Bandwidth={self.available_bandwidth}, Distance={self.network_distance}, \"\n",
    "                f\"Hosted_Services={len(self.hosted_services)})\")\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MICROSERVICE  \n",
    "class Microservice:\n",
    "    def __init__(self, service_id, name, cpu_requirement, memory_requirement, bandwidth_requirement, latency_threshold, server=None):\n",
    "        self.service_id = service_id\n",
    "        self.name = name\n",
    "        self.cpu_requirement = cpu_requirement\n",
    "        self.memory_requirement = memory_requirement\n",
    "        self.bandwidth_requirement = bandwidth_requirement\n",
    "        self.latency_threshold = latency_threshold\n",
    "        self.server = server  # HOST SERVER\n",
    "\n",
    "    def __str__(self):\n",
    "        server_id = self.server.server_id if self.server else \"Not deployed\"\n",
    "        return (f\"Microservice(name={self.name}, CPU={self.cpu_requirement}, \"\n",
    "                f\"Memory={self.memory_requirement}, Bandwidth={self.bandwidth_requirement}, \"\n",
    "                f\"Latency Threshold={self.latency_threshold}ms, Server={server_id})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH\n",
    "\n",
    "import heapq\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "class NetworkGraph:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}  # Stores server objects with server_id as key\n",
    "        self.edges = {}  # Stores connections and their properties\n",
    "\n",
    "    def add_server(self, server):\n",
    "        \"\"\"Add a server\"\"\"\n",
    "        self.nodes[server.server_id] = server\n",
    "        self.edges[server.server_id] = []\n",
    "\n",
    "    def connect_servers(self, server_id1, server_id2, latency, bandwidth):\n",
    "        \"\"\"Connect two servers with specified latency and bandwidth.\"\"\"\n",
    "        if server_id1 not in self.nodes or server_id2 not in self.nodes:\n",
    "            raise ValueError(\"One or both of the servers not found in the graph.\")\n",
    "        \n",
    "        connection_info = {'latency': latency, 'bandwidth': bandwidth}\n",
    "        self.edges[server_id1].append((server_id2, connection_info))\n",
    "        self.edges[server_id2].append((server_id1, connection_info))\n",
    "\n",
    "    def get_server_connections(self, server_id):\n",
    "        \"\"\"Retrieve a server's connections and their properties.\"\"\"\n",
    "        return self.edges.get(server_id, [])\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Provide a string overload of the graph for debugging purposes.\"\"\"\n",
    "        description = \"Network Graph:\\n\"\n",
    "        for server_id in self.nodes:\n",
    "            description += f\"Server {server_id} connections: {self.edges[server_id]}\\n\"\n",
    "        return description\n",
    "    \n",
    "    def find_shortest_path(self, start_server_id, end_server_id):\n",
    "        \"\"\"Find the shortest path from start to end server based on latency using Dijkstra\"\"\"\n",
    "        distances = {server_id: float('inf') for server_id in self.nodes}\n",
    "        distances[start_server_id] = 0\n",
    "        priority_queue = [(0, start_server_id)]\n",
    "        predecessor = {server_id: None for server_id in self.nodes}\n",
    "\n",
    "        while priority_queue:\n",
    "            current_distance, current_server_id = heapq.heappop(priority_queue)\n",
    "            if current_server_id == end_server_id:\n",
    "                break\n",
    "\n",
    "            for neighbor, connection_info in self.get_server_connections(current_server_id):\n",
    "                distance = current_distance + connection_info['latency']\n",
    "                if distance < distances[neighbor]:\n",
    "                    distances[neighbor] = distance\n",
    "                    predecessor[neighbor] = current_server_id\n",
    "                    heapq.heappush(priority_queue, (distance, neighbor))\n",
    "\n",
    "        # Reconstruct path\n",
    "        path = []\n",
    "        current = end_server_id\n",
    "        while current is not None:\n",
    "            path.append(current)\n",
    "            current = predecessor[current]\n",
    "        path.reverse()\n",
    "\n",
    "        return path if path[0] == start_server_id else None\n",
    "    \n",
    "    def average_network_latency(self):\n",
    "        \"\"\"Calculate the average latency across all connections in the graph.\"\"\"\n",
    "        total_latency, count = 0, 0\n",
    "        for server_id in self.edges:\n",
    "            for connection in self.edges[server_id]:\n",
    "                _, connection_info = connection\n",
    "                total_latency += connection_info['latency']\n",
    "                count += 1\n",
    "        return total_latency / count if count > 0 else 0\n",
    "    \n",
    "\n",
    "    def update_connection(self, server_id1, server_id2, latency=None, bandwidth=None):\n",
    "        \"\"\"Update the properties of a connection between two servers.\"\"\"\n",
    "        if server_id1 in self.edges and server_id2 in self.edges:\n",
    "            for i, (target_id, info) in enumerate(self.edges[server_id1]):\n",
    "                if target_id == server_id2:\n",
    "                    if latency is not None:\n",
    "                        self.edges[server_id1][i][1]['latency'] = latency\n",
    "                    if bandwidth is not None:\n",
    "                        self.edges[server_id1][i][1]['bandwidth'] = bandwidth\n",
    "                    break\n",
    "            # Bidirectional repeat for the reverse connection\n",
    "            for i, (target_id, info) in enumerate(self.edges[server_id2]):\n",
    "                if target_id == server_id1:\n",
    "                    if latency is not None:\n",
    "                        self.edges[server_id2][i][1]['latency'] = latency\n",
    "                    if bandwidth is not None:\n",
    "                        self.edges[server_id2][i][1]['bandwidth'] = bandwidth\n",
    "                    break\n",
    "        else:\n",
    "            raise ValueError(\"One or both of the servers not found in the graph.\")\n",
    "        \n",
    "    def visualize(self):\n",
    "        \"\"\"Visualize the network graph.\"\"\"\n",
    "        G = nx.Graph()\n",
    "        for server_id in self.nodes:\n",
    "            G.add_node(server_id)\n",
    "        for server_id, connections in self.edges.items():\n",
    "            for target_id, info in connections:\n",
    "                G.add_edge(server_id, target_id, weight=info['latency'])\n",
    "        \n",
    "        pos = nx.spring_layout(G)  # positions for all nodes\n",
    "        nx.draw_networkx_nodes(G, pos, node_size=700)\n",
    "        nx.draw_networkx_edges(G, pos, width=2)\n",
    "        nx.draw_networkx_labels(G, pos, font_size=10, font_family=\"sans-serif\")\n",
    "        \n",
    "        edge_labels = dict([((u, v,), f\"{d['weight']}ms\")\n",
    "                            for u, v, d in G.edges(data=True)])\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#ENVIRONMENT\n",
    "\n",
    "class MicroserviceDeploymentEnv:\n",
    "    def __init__(self, graph, microservices):\n",
    "        self.graph = graph  \n",
    "        self.microservices = microservices\n",
    "        self.current_microservice = None\n",
    "        self.state_size = None\n",
    "        self.action_size = len(graph.nodes)  # Dynamically determined by the number of servers in the graph\n",
    "\n",
    "  \n",
    "\n",
    "    @staticmethod        \n",
    "    def  normalize(value, min_value, max_value):\n",
    "        \"\"\"Normalize a value to 0-1 range for optimal dqn input\"\"\"\n",
    "\n",
    "        return (value - min_value) / (max_value - min_value) if max_value > min_value else 0\n",
    "    \n",
    "\n",
    "    def get_state(self, microservice):\n",
    "        state = []\n",
    "        # Add server states\n",
    "        for server_id, server in self.graph.nodes.items():\n",
    "            normalized_cpu = self.normalize(server.available_cpu, 0, server.total_cpu)\n",
    "            normalized_memory = self.normalize(server.available_memory, 0, server.total_memory)\n",
    "            normalized_bandwidth = self.normalize(server.available_bandwidth, 0, server.total_bandwidth)\n",
    "\n",
    "            server_state = [\n",
    "                normalized_cpu,  \n",
    "                normalized_memory,\n",
    "                normalized_bandwidth,\n",
    "                self.graph.get_average_latency_to_other_servers(server_id)\n",
    "            ]\n",
    "            state.extend(server_state)\n",
    "        # Add microservice requirements\n",
    "        microservice_state = [\n",
    "            microservice.cpu_requirement,\n",
    "            microservice.memory_requirement,\n",
    "            microservice.bandwidth_requirement,\n",
    "            microservice.latency_threshold\n",
    "        ]\n",
    "        # Normalize and add to state\n",
    "        state.extend([self.normalize(val, min_val, max_val) for val, min_val, max_val in zip(microservice_state, min_vals, max_vals)])\n",
    "        # Add global network metric\n",
    "        state.append(self.graph.average_network_latency())\n",
    "        return state\n",
    "\n",
    "    def execute_action(self, action):\n",
    "        # Action is the index corresponding to a server in the graph.nodes dictionary\n",
    "        server_ids = list(self.graph.nodes.keys())\n",
    "        try:\n",
    "            selected_server_id = server_ids[action] \n",
    "            selected_server = self.graph.nodes[selected_server_id]\n",
    "            #deploy the microservice to the selected server\n",
    "            if self.current_microservice and selected_server.meets_requirements(\n",
    "                self.current_microservice.cpu_requirement,\n",
    "                self.current_microservice.memory_requirement,\n",
    "                self.current_microservice.bandwidth_requirement\n",
    "            ):\n",
    "                success = selected_server.deploy_microservice(self.current_microservice)\n",
    "                if success:\n",
    "                    return self.calculate_reward(action, success)  # Return True if deployment is successful\n",
    "                \n",
    "        except IndexError:\n",
    "            # Handle invalid action (e.g., action index out of range)\n",
    "            pass\n",
    "\n",
    "        return self.calculate_reward(action, success)   # Return False if deployment fails or is invalid\n",
    "    \n",
    "    def calculate_reward(self, action, success):\n",
    "        \"\"\"\n",
    "        Calculate the reward for deploying a microservice based on the action's success and system state.\n",
    "        \n",
    "        Parameters:\n",
    "            action (int): The destination server of the action attempted\n",
    "            success: Whether the microservice deployment was successful.\n",
    "        \n",
    "        Returns the calculated reward for the action.\n",
    "             \n",
    "        \"\"\"\n",
    "        if not self.current_microservice:\n",
    "            # No microservice is selected for deployment...system error.\n",
    "            return -10  # Penalize heavily\n",
    "        \n",
    "        server_ids = list(self.graph.nodes.keys())\n",
    "        try:\n",
    "            selected_server_id = server_ids[action]\n",
    "            selected_server = self.graph.nodes[selected_server_id]\n",
    "        except IndexError:\n",
    "            # Action led to an invalid server selection\n",
    "            return -5\n",
    "        \n",
    "        if not success:\n",
    "            # Deployment failed. Penalize to a degree but less than system errors.\n",
    "            return -2\n",
    "\n",
    "        # If deployment was successful, positive reward is calculated based on several factors, we can supplement it if necessary\n",
    "        reward = 0\n",
    "        \n",
    "        # Factor 1: Resource Utilization Efficiency. Encourage efficient use of server resources without overloading.\n",
    "\n",
    "        cpu_utilization = (selected_server.total_cpu - selected_server.available_cpu) / selected_server.total_cpu\n",
    "        memory_utilization = (selected_server.total_memory - selected_server.available_memory) / selected_server.total_memory\n",
    "        bandwidth_utilization = (selected_server.total_bandwidth - selected_server.available_bandwidth) / selected_server.total_bandwidth\n",
    "        \n",
    "        # Average utilization leads to balanced use of resources.\n",
    "        avg_utilization = (cpu_utilization + memory_utilization + bandwidth_utilization) / 3\n",
    "        reward += 5 * avg_utilization  \n",
    "        \n",
    "        # Factor 2: Network Performance. Penalize if the deployment significantly impacts network latency or does not meet latency requirements.\n",
    "\n",
    "        if selected_server.calculate_latency_priority(self.current_microservice) > self.current_microservice.latency_threshold:\n",
    "            # Penalize for exceeding latency threshold, scaled by how much it was exceeded.\n",
    "            reward -= 5 * (selected_server.calculate_latency_priority(self.current_microservice) / self.current_microservice.latency_threshold)\n",
    "        \n",
    "        # Factor 3: Load Balancing. Reward deployments that help balance the load across the network.\n",
    "        \n",
    "        load_imbalance = self.calculate_load_imbalance()  # Hypothetical function to assess load balance across servers.\n",
    "        reward -= 2 * load_imbalance  # Penalize based on degree of imbalance to encourage load balancing.\n",
    "        \n",
    "        # OTHERS\n",
    "        \n",
    "        return reward\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before deployment:\n",
      "Server(ID=server1, IP=192.168.1.1, CPU=100, Memory=256, Bandwidth=1000, Distance=10, Hosted_Services=0)\n",
      "Server(ID=server2, IP=192.168.1.2, CPU=200, Memory=512, Bandwidth=2000, Distance=20, Hosted_Services=0)\n",
      "Deployed service1 to server1 with reward: 0.16986666666666667\n",
      "Deployed service2 to server2 with reward: 0.09504987765857331\n",
      "Deployed service3 to server1 with reward: 0.16979329511898558\n",
      "Deployed service4 to server1 with reward: -1\n",
      "Deployed service5 to server2 with reward: 0.09485645933014354\n",
      "Deployed service6 to server2 with reward: 0.09658016841381681\n",
      "Deployed service7 to server1 with reward: -1\n",
      "Deployed service8 to server1 with reward: -1\n",
      "Deployed service9 to server1 with reward: -1\n",
      "Deployed service10 to server1 with reward: -1\n",
      "Deployed service11 to server2 with reward: 0.09927729174591099\n",
      "Deployed service12 to server2 with reward: 0.15031503150315031\n",
      "Deployed service13 to server2 with reward: -1\n",
      "Deployed service14 to server1 with reward: -1\n",
      "Deployed service15 to server1 with reward: -1\n",
      "Deployed service16 to server2 with reward: -1\n",
      "Deployed service17 to server1 with reward: -1\n",
      "Deployed service18 to server1 with reward: -1\n",
      "Deployed service19 to server1 with reward: -1\n",
      "Deployed service20 to server2 with reward: -1\n",
      "Deployed service21 to server2 with reward: -1\n",
      "Deployed service22 to server1 with reward: -1\n",
      "Deployed service23 to server2 with reward: -1\n",
      "Deployed service24 to server2 with reward: -1\n",
      "Deployed service25 to server2 with reward: -1\n",
      "Deployed service26 to server2 with reward: -1\n",
      "Deployed service27 to server2 with reward: -1\n",
      "Deployed service28 to server2 with reward: -1\n",
      "Deployed service29 to server2 with reward: -1\n",
      "Deployed service30 to server2 with reward: -1\n",
      "Deployed service31 to server1 with reward: -1\n",
      "Deployed service32 to server1 with reward: -1\n",
      "Deployed service33 to server1 with reward: -1\n",
      "Deployed service34 to server1 with reward: -1\n",
      "Deployed service35 to server1 with reward: -1\n",
      "Deployed service36 to server2 with reward: -1\n",
      "Deployed service37 to server2 with reward: -1\n",
      "Deployed service38 to server1 with reward: -1\n",
      "Deployed service39 to server2 with reward: -1\n",
      "Deployed service40 to server2 with reward: -1\n",
      "Deployed service41 to server2 with reward: -1\n",
      "Deployed service42 to server2 with reward: -1\n",
      "Deployed service43 to server1 with reward: -1\n",
      "Deployed service44 to server1 with reward: -1\n",
      "Deployed service45 to server1 with reward: -1\n",
      "Deployed service46 to server2 with reward: -1\n",
      "Deployed service47 to server2 with reward: -1\n",
      "Deployed service48 to server1 with reward: -1\n",
      "Deployed service49 to server2 with reward: -1\n",
      "Deployed service50 to server2 with reward: -1\n",
      "\n",
      "After deployment:\n",
      "Server(ID=server1, IP=192.168.1.1, CPU=31, Memory=56, Bandwidth=286, Distance=10, Hosted_Services=2)\n",
      "Server(ID=server2, IP=192.168.1.2, CPU=79, Memory=41, Bandwidth=348, Distance=20, Hosted_Services=5)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sample_test():\n",
    "    # Initialize servers as a dictionary\n",
    "    servers = {\n",
    "        \"server1\": Server(\"server1\", \"192.168.1.1\", 100, 256, 1000, 10),\n",
    "        \"server2\": Server(\"server2\", \"192.168.1.2\", 200, 512, 2000, 20),\n",
    "    }\n",
    "\n",
    "    # Generating 50 microservices\n",
    "    microservices = [\n",
    "        Microservice(f\"service{i}\", f\"Service{i}\", random.randint(10, 50), random.randint(64, 128), random.randint(200, 500), random.randint(1, 5))\n",
    "        for i in range(1, 51)\n",
    "    ]\n",
    "\n",
    "    # Create the environment\n",
    "    env = MicroserviceDeploymentEnv(servers, microservices)\n",
    "    \n",
    "    print(\"Before deployment:\")\n",
    "    for server_id, server in env.servers.items():\n",
    "        print(server)\n",
    "\n",
    "    # Deploy each microservice to a randomly chosen server\n",
    "    for microservice in microservices:\n",
    "        selected_server_id = random.choice(list(env.servers.keys()))  # Randomly select a server\n",
    "        reward = env.deploy_microservice_to_server(microservice.service_id, selected_server_id)\n",
    "        print(f\"Deployed {microservice.service_id} to {selected_server_id} with reward: {reward}\")\n",
    "\n",
    "    print(\"\\nAfter deployment:\")\n",
    "    for server_id, server in env.servers.items():\n",
    "        print(server)\n",
    "\n",
    "# Run the sample test\n",
    "sample_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
